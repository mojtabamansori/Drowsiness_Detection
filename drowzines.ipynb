{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10877bbf",
   "metadata": {
    "papermill": {
     "duration": 0.003351,
     "end_time": "2026-01-03T19:51:27.537707",
     "exception": false,
     "start_time": "2026-01-03T19:51:27.534356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 0 — Pipeline Switches (0/1)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23dc05b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:51:27.544219Z",
     "iopub.status.busy": "2026-01-03T19:51:27.543969Z",
     "iopub.status.idle": "2026-01-03T19:51:39.931491Z",
     "shell.execute_reply": "2026-01-03T19:51:39.930645Z"
    },
    "papermill": {
     "duration": 12.393088,
     "end_time": "2026-01-03T19:51:39.933302",
     "exception": false,
     "start_time": "2026-01-03T19:51:27.540214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 173M\r\n",
      "-rw-r--r-- 1 root root 173M Jan  3 19:51 dataset.mat\r\n",
      "---------- 1 root root  34K Jan  3 19:51 __notebook__.ipynb\r\n",
      "\n",
      "✓ Dataset copied\n"
     ]
    }
   ],
   "source": [
    "# Pipeline mode:\n",
    "# 0 = CNN on time-series (your current Torch training)\n",
    "# 1 = Feature-based ML (Logistic Regression with optional feature selection + postprocess)\n",
    "PIPELINE_MODE = 1\n",
    "\n",
    "# 0/1 switches\n",
    "ENABLE_BIPOLAR = 1\n",
    "ENABLE_OVERLAP_AUGMENT = 1\n",
    "ENABLE_WITHIN_SUBJECT_STANDARDIZE = 1\n",
    "\n",
    "ENABLE_FEATURE_EXTRACTION = 0\n",
    "ENABLE_FEATURE_SELECTION = 0\n",
    "ENABLE_POSTPROCESSING = 1\n",
    "\n",
    "# Recommended consistent settings:\n",
    "# - CNN pipeline: PIPELINE_MODE=0, ENABLE_FEATURE_EXTRACTION=0, ENABLE_FEATURE_SELECTION=0\n",
    "# - Feature pipeline: PIPELINE_MODE=1, ENABLE_FEATURE_EXTRACTION=1, ENABLE_FEATURE_SELECTION=1\n",
    "\n",
    "# Feature extraction settings (used when ENABLE_FEATURE_EXTRACTION=1)\n",
    "FS = 128.0  # sampling rate (Hz). Change if your dataset uses a different FS.\n",
    "\n",
    "BANDS = {\n",
    "    \"delta\": (0.5, 4.0),\n",
    "    \"theta\": (4.0, 8.0),\n",
    "    \"alpha\": (8.0, 13.0),\n",
    "    \"beta\":  (13.0, 30.0),\n",
    "    \"gamma\": (30.0, 45.0),\n",
    "}\n",
    "\n",
    "# Feature selection settings (used when ENABLE_FEATURE_SELECTION=1)\n",
    "FEATURE_SELECTION_METHOD = \"f_classif\"  # \"f_classif\" or \"mutual_info\"\n",
    "FEATURE_K = 200  # number of selected features (top-K)\n",
    "\n",
    "# Post-processing settings (used when ENABLE_POSTPROCESSING=1)\n",
    "SMOOTH_WINDOW = 5  # odd integer recommended (e.g., 3,5,7)\n",
    "\n",
    "# Training settings\n",
    "N_RUNS = 11\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Torch CNN settings (PIPELINE_MODE=0)\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "N_EPOCHS = 15\n",
    "\n",
    "# --------- IMPORTANT: Keep your original cell structure + naming intact ---------\n",
    "# (As requested, I won't rename or re-section any cells.)\n",
    "\n",
    "!cp \"/kaggle/input/dataset-drowsiness/dataset (1).mat\" /kaggle/working/dataset.mat\n",
    "\n",
    "# Check\n",
    "!ls -lh /kaggle/working/\n",
    "print(\"\\n✓ Dataset copied\")\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_COMPILE_DISABLE'] = '1'\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "\n",
    "import torch\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "\n",
    "# --- Post-processing utility (defined early so it can be used during evaluation) ---\n",
    "def smooth_predictions(pred, window=5):\n",
    "    pred = np.asarray(pred).astype(int)\n",
    "    if window is None or window <= 1:\n",
    "        return pred\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "\n",
    "    pad = window // 2\n",
    "    padded = np.pad(pred, (pad, pad), mode=\"edge\")\n",
    "    out = pred.copy()\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        w = padded[i:i + window]\n",
    "        out[i] = 1 if np.mean(w) >= 0.5 else 0\n",
    "    return out\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# Electrode indices\n",
    "fp1, fp2, f7 = 0, 1, 2\n",
    "f3, fz, f4 = 3, 4, 5\n",
    "f8, ft7, fc3 = 6, 7, 8\n",
    "fcz, fc4, ft8 = 9, 10, 11\n",
    "t3, c3, cz = 12, 13, 14\n",
    "c4, t4, tp7 = 15, 16, 17\n",
    "cp3, cpz, cp4 = 18, 19, 20\n",
    "tp8a1, t5, p3 = 21, 22, 23\n",
    "pz, p4, t6a2 = 24, 25, 26\n",
    "o1, oz, o2 = 27, 28, 29\n",
    "\n",
    "# Subject boundaries (original sample indices)\n",
    "startsub = np.zeros(11)\n",
    "finalsub = np.zeros(11)\n",
    "startsub[0] = 0\n",
    "finalsub[0] = 89\n",
    "startsub[1] = finalsub[0]\n",
    "finalsub[1] = 468\n",
    "startsub[2] = finalsub[1]\n",
    "finalsub[2] = 642\n",
    "startsub[3] = finalsub[2]\n",
    "finalsub[3] = 757\n",
    "startsub[4] = finalsub[3]\n",
    "finalsub[4] = 842\n",
    "startsub[5] = finalsub[4]\n",
    "finalsub[5] = 1008\n",
    "startsub[6] = finalsub[5]\n",
    "finalsub[6] = 1110\n",
    "startsub[7] = finalsub[6]\n",
    "finalsub[7] = 1374\n",
    "startsub[8] = finalsub[7]\n",
    "finalsub[8] = 1688\n",
    "startsub[9] = finalsub[8]\n",
    "finalsub[9] = 1796\n",
    "startsub[10] = finalsub[9]\n",
    "finalsub[10] = 2022\n",
    "\n",
    "\n",
    "def bipolar(xdata):\n",
    "    xdatabipolar = np.zeros((2022, 32, 384))\n",
    "    # vertical\n",
    "    # 1\n",
    "    xdatabipolar[:, 0, :] = xdata[:, fp1, :] - xdata[:, f7, :]\n",
    "    xdatabipolar[:, 1, :] = xdata[:, f7, :] - xdata[:, t3, :]\n",
    "    xdatabipolar[:, 2, :] = xdata[:, t3, :] - xdata[:, t5, :]\n",
    "    xdatabipolar[:, 3, :] = xdata[:, t5, :] - xdata[:, o1, :]\n",
    "    xdatabipolar[:, 4, :] = xdata[:, o1, :] - xdata[:, p3, :]\n",
    "    xdatabipolar[:, 5, :] = xdata[:, p3, :] - xdata[:, c3, :]\n",
    "    xdatabipolar[:, 6, :] = xdata[:, c3, :] - xdata[:, f3, :]\n",
    "    xdatabipolar[:, 7, :] = xdata[:, f3, :] - xdata[:, fp1, :]\n",
    "    # 2\n",
    "    xdatabipolar[:, 8, :] = xdata[:, pz, :] - xdata[:, cz, :]\n",
    "    xdatabipolar[:, 9, :] = xdata[:, cz, :] - xdata[:, fz, :]\n",
    "    # 3\n",
    "    xdatabipolar[:, 10, :] = xdata[:, fp2, :] - xdata[:, f8, :]\n",
    "    xdatabipolar[:, 11, :] = xdata[:, f8, :] - xdata[:, t4, :]\n",
    "    xdatabipolar[:, 12, :] = xdata[:, t4, :] - xdata[:, tp8a1, :]\n",
    "    xdatabipolar[:, 13, :] = xdata[:, tp8a1, :] - xdata[:, o2, :]\n",
    "    xdatabipolar[:, 14, :] = xdata[:, o2, :] - xdata[:, p4, :]\n",
    "    xdatabipolar[:, 15, :] = xdata[:, p4, :] - xdata[:, c4, :]\n",
    "    xdatabipolar[:, 16, :] = xdata[:, c4, :] - xdata[:, f4, :]\n",
    "    xdatabipolar[:, 17, :] = xdata[:, f4, :] - xdata[:, fp2, :]\n",
    "\n",
    "    # horizontal\n",
    "    # 1\n",
    "    xdatabipolar[:, 18, :] = xdata[:, fp1, :] - xdata[:, f3, :]\n",
    "    xdatabipolar[:, 19, :] = xdata[:, f3, :] - xdata[:, c3, :]\n",
    "    xdatabipolar[:, 20, :] = xdata[:, c3, :] - xdata[:, p3, :]\n",
    "    xdatabipolar[:, 21, :] = xdata[:, p3, :] - xdata[:, o1, :]\n",
    "\n",
    "    # 2\n",
    "    xdatabipolar[:, 22, :] = xdata[:, fp2, :] - xdata[:, f4, :]\n",
    "    xdatabipolar[:, 23, :] = xdata[:, f4, :] - xdata[:, c4, :]\n",
    "    xdatabipolar[:, 24, :] = xdata[:, c4, :] - xdata[:, p4, :]\n",
    "    xdatabipolar[:, 25, :] = xdata[:, p4, :] - xdata[:, o2, :]\n",
    "\n",
    "    # 3\n",
    "    xdatabipolar[:, 26, :] = xdata[:, f7, :] - xdata[:, fc3, :]\n",
    "    xdatabipolar[:, 27, :] = xdata[:, fc3, :] - xdata[:, t3, :]\n",
    "    xdatabipolar[:, 28, :] = xdata[:, t3, :] - xdata[:, cp3, :]\n",
    "    xdatabipolar[:, 29, :] = xdata[:, cp3, :] - xdata[:, t5, :]\n",
    "\n",
    "    # 4\n",
    "    xdatabipolar[:, 30, :] = xdata[:, f8, :] - xdata[:, fc4, :]\n",
    "    xdatabipolar[:, 31, :] = xdata[:, fc4, :] - xdata[:, t4, :]\n",
    "\n",
    "    return xdatabipolar\n",
    "\n",
    "\n",
    "def overlap_data(xdata, label):\n",
    "    newdata = np.zeros((6064, xdata.shape[1], xdata.shape[2]))\n",
    "    newlabel = np.zeros((6064,))\n",
    "    leni1 = 0\n",
    "    for iindex in range(0, 11):\n",
    "        s = startsub[iindex]\n",
    "        f = finalsub[iindex]\n",
    "        leni2 = leni1 + int(f - s)\n",
    "        for i in range(leni1, leni2 - 1):\n",
    "            newdata[(3 * i), :, :] = xdata[i, :, :]\n",
    "\n",
    "            newdata[(3 * i) + 1, :, :256] = xdata[i, :, 128:]\n",
    "            newdata[(3 * i) + 1, :, 256:] = xdata[i + 1, :, :128]\n",
    "\n",
    "            newdata[(3 * i) + 2, :, :128] = xdata[i, :, 256:]\n",
    "            newdata[(3 * i) + 2, :, 128:] = xdata[i + 1, :, :256]\n",
    "\n",
    "        for i in range(leni1, leni2 - 1):\n",
    "            newlabel[(3 * i)] = label[i]\n",
    "            newlabel[(3 * i) + 1] = label[i]\n",
    "            newlabel[(3 * i) + 2] = label[i + 1]\n",
    "\n",
    "        leni1 = leni2\n",
    "    return newdata, newlabel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8a4c7a",
   "metadata": {
    "papermill": {
     "duration": 0.002473,
     "end_time": "2026-01-03T19:51:39.938560",
     "exception": false,
     "start_time": "2026-01-03T19:51:39.936087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 1 — Preprocessing\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0b010ad",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-03T19:51:39.944787Z",
     "iopub.status.busy": "2026-01-03T19:51:39.944432Z",
     "iopub.status.idle": "2026-01-03T19:51:42.958391Z",
     "shell.execute_reply": "2026-01-03T19:51:42.957469Z"
    },
    "papermill": {
     "duration": 3.019023,
     "end_time": "2026-01-03T19:51:42.960085",
     "exception": false,
     "start_time": "2026-01-03T19:51:39.941062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "کلیدهای داخل فایل: ['EEGsample', 'subindex', 'substate']\n",
      "data shape: (2022, 30, 384)\n",
      "labels shape: (2022,)\n",
      "processed_data: (6064, 32, 384) processed_labels: (6064,) subIdx: (6064,)\n"
     ]
    }
   ],
   "source": [
    "mat_path = \"/kaggle/input/dataset-drowsiness/dataset (1).mat\"\n",
    "mat_contents = sio.loadmat(mat_path, squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "# کلیدهای فایل (برای چک)\n",
    "keys = [k for k in mat_contents.keys() if not k.startswith(\"__\")]\n",
    "print(\"کلیدهای داخل فایل:\", keys)\n",
    "\n",
    "# داده و برچسب مطابق فایل تو\n",
    "data = np.array(mat_contents[\"EEGsample\"])          # (2022, 30, 384)\n",
    "labels = np.array(mat_contents[\"substate\"]).reshape(-1)  # (2022,)\n",
    "\n",
    "print(\"data shape:\", data.shape)\n",
    "print(\"labels shape:\", labels.shape)\n",
    "\n",
    "# Create subject index vector (1..11) aligned to your startsub/finalsub\n",
    "subIdx = np.zeros((2022,), dtype=int)\n",
    "for si in range(11):\n",
    "    s = int(startsub[si]); f = int(finalsub[si])\n",
    "    subIdx[s:f] = si + 1\n",
    "\n",
    "processed_data = data.copy()\n",
    "processed_labels = labels.copy()\n",
    "\n",
    "if ENABLE_BIPOLAR == 1:\n",
    "    processed_data = bipolar(processed_data)\n",
    "\n",
    "if ENABLE_OVERLAP_AUGMENT == 1:\n",
    "    processed_data, processed_labels = overlap_data(processed_data, processed_labels)\n",
    "\n",
    "    # rebuild subject groups for augmented samples\n",
    "    base_idx = np.minimum(np.arange(processed_data.shape[0]) // 3, 2021)\n",
    "    subIdx = subIdx[base_idx]\n",
    "\n",
    "if ENABLE_WITHIN_SUBJECT_STANDARDIZE == 1:\n",
    "    # standardize per subject across time for each channel\n",
    "    x = processed_data\n",
    "    for subj in range(1, 12):\n",
    "        mask = (subIdx == subj)\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "        xs = x[mask]  # (n, ch, t)\n",
    "        mean = xs.mean(axis=(0, 2), keepdims=True)\n",
    "        std = xs.std(axis=(0, 2), keepdims=True) + 1e-12\n",
    "        x[mask] = (xs - mean) / std\n",
    "    processed_data = x\n",
    "\n",
    "print(\"processed_data:\", processed_data.shape, \"processed_labels:\", processed_labels.shape, \"subIdx:\", subIdx.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569ae5d7",
   "metadata": {
    "papermill": {
     "duration": 0.002812,
     "end_time": "2026-01-03T19:51:42.965953",
     "exception": false,
     "start_time": "2026-01-03T19:51:42.963141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 2 — Feature Extraction\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1d1ee86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:51:42.972316Z",
     "iopub.status.busy": "2026-01-03T19:51:42.972039Z",
     "iopub.status.idle": "2026-01-03T19:52:43.024690Z",
     "shell.execute_reply": "2026-01-03T19:52:43.023993Z"
    },
    "papermill": {
     "duration": 60.060536,
     "end_time": "2026-01-03T19:52:43.029023",
     "exception": false,
     "start_time": "2026-01-03T19:51:42.968487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[استخراج ویژگی] چون مسیر ویژگی فعال است، استخراج ویژگی به صورت خودکار روشن شد\n",
      "[Feature Extraction] Computing EEG features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/367013577.py:5: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return np.trapz(psd[mask], freqs[mask])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Extraction] feature_X shape: (6064, 352)\n"
     ]
    }
   ],
   "source": [
    "def _bandpower_from_psd(freqs, psd, fmin, fmax):\n",
    "    mask = (freqs >= fmin) & (freqs < fmax)\n",
    "    if not np.any(mask):\n",
    "        return 0.0\n",
    "    return np.trapz(psd[mask], freqs[mask])\n",
    "\n",
    "def _hjorth_params(x):\n",
    "    x = np.asarray(x)\n",
    "    dx = np.diff(x)\n",
    "    ddx = np.diff(dx)\n",
    "    var_x = np.var(x) + 1e-12\n",
    "    var_dx = np.var(dx) + 1e-12\n",
    "    var_ddx = np.var(ddx) + 1e-12\n",
    "    activity = var_x\n",
    "    mobility = np.sqrt(var_dx / var_x)\n",
    "    complexity = np.sqrt(var_ddx / var_dx) / (mobility + 1e-12)\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "def extract_eeg_features(X, fs, bands):\n",
    "    # X: (n_samples, n_channels, n_times)\n",
    "    n, c, t = X.shape\n",
    "    feats = []\n",
    "    freqs = np.fft.rfftfreq(t, d=1.0/fs)\n",
    "\n",
    "    for i in range(n):\n",
    "        sample_feats = []\n",
    "        for ch in range(c):\n",
    "            x = X[i, ch, :]\n",
    "            fft = np.fft.rfft(x)\n",
    "            psd = (np.abs(fft) ** 2) / (t + 1e-12)\n",
    "\n",
    "            # Relative band powers\n",
    "            total = _bandpower_from_psd(freqs, psd, 0.5, 45.0) + 1e-12\n",
    "            rel = []\n",
    "            for _, (fmin, fmax) in bands.items():\n",
    "                bp = _bandpower_from_psd(freqs, psd, fmin, fmax)\n",
    "                rel.append(bp / total)\n",
    "\n",
    "            # Ratios\n",
    "            theta_alpha = (rel[list(bands.keys()).index(\"theta\")] + 1e-12) / (rel[list(bands.keys()).index(\"alpha\")] + 1e-12)\n",
    "            theta_beta  = (rel[list(bands.keys()).index(\"theta\")] + 1e-12) / (rel[list(bands.keys()).index(\"beta\")] + 1e-12)\n",
    "\n",
    "            # Hjorth\n",
    "            act, mob, comp = _hjorth_params(x)\n",
    "\n",
    "            # Spectral entropy\n",
    "            p = psd / (np.sum(psd) + 1e-12)\n",
    "            spec_entropy = -np.sum(p * np.log(p + 1e-12)) / (np.log(len(p)) + 1e-12)\n",
    "\n",
    "            sample_feats.extend(rel)\n",
    "            sample_feats.extend([theta_alpha, theta_beta])\n",
    "            sample_feats.extend([act, mob, comp])\n",
    "            sample_feats.append(spec_entropy)\n",
    "\n",
    "        feats.append(sample_feats)\n",
    "\n",
    "    return np.asarray(feats, dtype=np.float64)\n",
    "\n",
    "feature_X = None\n",
    "feature_y = None\n",
    "feature_groups = None\n",
    "\n",
    "\n",
    "# اگر مسیر ویژگی فعال باشد ولی استخراج ویژگی خاموش باشد، برای جلوگیری از توقف برنامه آن را روشن می‌کنیم\n",
    "if PIPELINE_MODE == 1 and ENABLE_FEATURE_EXTRACTION == 0:\n",
    "    print(\"[استخراج ویژگی] چون مسیر ویژگی فعال است، استخراج ویژگی به صورت خودکار روشن شد\")\n",
    "    ENABLE_FEATURE_EXTRACTION = 1\n",
    "\n",
    "if ENABLE_FEATURE_EXTRACTION == 1:\n",
    "    print(\"[Feature Extraction] Computing EEG features...\")\n",
    "    feature_X = extract_eeg_features(processed_data, FS, BANDS)\n",
    "    feature_y = processed_labels.astype(int).copy()\n",
    "    feature_groups = subIdx.astype(int).copy()\n",
    "    print(f\"[Feature Extraction] feature_X shape: {feature_X.shape}\")\n",
    "else:\n",
    "    print(\"[Feature Extraction] Disabled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed908e8",
   "metadata": {
    "papermill": {
     "duration": 0.002745,
     "end_time": "2026-01-03T19:52:43.034446",
     "exception": false,
     "start_time": "2026-01-03T19:52:43.031701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 3 — Feature Selection\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e366f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:52:43.040744Z",
     "iopub.status.busy": "2026-01-03T19:52:43.040492Z",
     "iopub.status.idle": "2026-01-03T19:52:43.187346Z",
     "shell.execute_reply": "2026-01-03T19:52:43.186545Z"
    },
    "papermill": {
     "duration": 0.152009,
     "end_time": "2026-01-03T19:52:43.189013",
     "exception": false,
     "start_time": "2026-01-03T19:52:43.037004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def fit_transform_selector(X_train, y_train, X_test, method=\"f_classif\", k=200):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    if k is None or k <= 0 or k >= X_train_s.shape[1]:\n",
    "        return X_train_s, X_test_s, scaler, None\n",
    "\n",
    "    if method == \"mutual_info\":\n",
    "        selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    else:\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "\n",
    "    X_train_k = selector.fit_transform(X_train_s, y_train)\n",
    "    X_test_k = selector.transform(X_test_s)\n",
    "    return X_train_k, X_test_k, scaler, selector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cddcd1c",
   "metadata": {
    "papermill": {
     "duration": 0.002631,
     "end_time": "2026-01-03T19:52:43.194480",
     "exception": false,
     "start_time": "2026-01-03T19:52:43.191849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 4 — Model Training\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ec8fab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:52:43.201327Z",
     "iopub.status.busy": "2026-01-03T19:52:43.200940Z",
     "iopub.status.idle": "2026-01-03T19:57:38.831258Z",
     "shell.execute_reply": "2026-01-03T19:57:38.828961Z"
    },
    "papermill": {
     "duration": 295.636182,
     "end_time": "2026-01-03T19:57:38.833373",
     "exception": false,
     "start_time": "2026-01-03T19:52:43.197191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "\n",
      "Run 1/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 2/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 3/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 4/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 5/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 6/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 7/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 8/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 9/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 10/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n",
      "\n",
      "Run 11/11\n",
      "  Subject  1: raw=0.4045 | smooth=0.3820\n",
      "  Subject  2: raw=0.6394 | smooth=0.6640\n",
      "  Subject  3: raw=0.8103 | smooth=0.8295\n",
      "  Subject  4: raw=0.6899 | smooth=0.7217\n",
      "  Subject  5: raw=0.4863 | smooth=0.4863\n",
      "  Subject  6: raw=0.7731 | smooth=0.8273\n",
      "  Subject  7: raw=0.6176 | smooth=0.6275\n",
      "  Subject  8: raw=0.5657 | smooth=0.5657\n",
      "  Subject  9: raw=0.7994 | smooth=0.8556\n",
      "  Subject 10: raw=0.8056 | smooth=0.8241\n",
      "  Subject 11: raw=0.5843 | smooth=0.6050\n",
      "Run mean (raw): 0.6524\n",
      "Run mean (smooth): 0.6717\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "# Storage for results\n",
    "all_results_raw = np.zeros((N_RUNS, 11), dtype=float)\n",
    "all_results_smooth = np.full((N_RUNS, 11), np.nan, dtype=float)\n",
    "\n",
    "# Store detailed rows for Excel export\n",
    "fold_rows = []\n",
    "\n",
    "# Optional: store predictions to inspect later (per run, per subject)\n",
    "stored_predictions = {}\n",
    "\n",
    "# Define CNN model only if used\n",
    "class InterpretableCNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.temporal = nn.Conv2d(1, 8, kernel_size=(1, 64), stride=(1, 1), padding=(0, 32), bias=False)\n",
    "        self.spatial = nn.Conv2d(8, 16, kernel_size=(n_channels, 1), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(1, 8), stride=(1, 8))\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(16 * (processed_data.shape[2] // 8), 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.temporal(x)\n",
    "        x = self.spatial(x)\n",
    "        x = self.bn(x)\n",
    "        x = x ** 2\n",
    "        x = self.pool(x)\n",
    "        x = torch.log(torch.clamp(x, min=1e-6))\n",
    "        x = self.drop(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)\n",
    "\n",
    "# LOSO for each run (different random_state for LR, CNN shuffle)\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"\\nRun {run+1}/{N_RUNS}\")\n",
    "    for test_subj in range(1, 12):\n",
    "        test_idx = np.where(subIdx == test_subj)[0]\n",
    "        train_mask = (subIdx != test_subj)\n",
    "\n",
    "        if PIPELINE_MODE == 0:\n",
    "            # CNN on raw time-series\n",
    "            X_train = processed_data[train_mask]\n",
    "            y_train = processed_labels[train_mask].astype(int)\n",
    "            X_test = processed_data[test_idx]\n",
    "            y_test = processed_labels[test_idx].astype(int)\n",
    "\n",
    "            # Torch expects (N, 1, C, T)\n",
    "            X_train_t = torch.tensor(X_train).unsqueeze(1).double()\n",
    "            y_train_t = torch.tensor(y_train).long()\n",
    "            X_test_t = torch.tensor(X_test).unsqueeze(1).double()\n",
    "            y_test_t = torch.tensor(y_test).long()\n",
    "\n",
    "            train_dataset = torch.utils.data.TensorDataset(X_train_t, y_train_t)\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "            )\n",
    "\n",
    "            n_channels = X_train.shape[1]\n",
    "            model = InterpretableCNN(n_channels=n_channels).double().to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            criterion = nn.NLLLoss()\n",
    "\n",
    "            model.train()\n",
    "            for epoch in range(N_EPOCHS):\n",
    "                for batch_x, batch_y in train_loader:\n",
    "                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(X_test_t.to(device))\n",
    "                pred_raw = torch.argmax(logits, dim=1).cpu().numpy().astype(int)\n",
    "                y_true = y_test.astype(int)\n",
    "                acc_raw = accuracy_score(y_true, pred_raw)\n",
    "\n",
    "            pred_smooth = None\n",
    "            acc_smooth = np.nan\n",
    "            if ENABLE_POSTPROCESSING == 1:\n",
    "                pred_smooth = smooth_predictions(pred_raw, window=SMOOTH_WINDOW).astype(int)\n",
    "                acc_smooth = accuracy_score(y_true, pred_smooth)\n",
    "\n",
    "        else:\n",
    "            # Feature-based ML\n",
    "            if feature_X is None or feature_y is None or feature_groups is None:\n",
    "                raise RuntimeError(\"ویژگی‌ها ساخته نشده‌اند. مطمئن شو که دادهٔ ورودی درست خوانده شده و بخش استخراج ویژگی اجرا شده است.\")\n",
    "\n",
    "            X_train = feature_X[train_mask]\n",
    "            y_train = feature_y[train_mask].astype(int)\n",
    "\n",
    "            X_test = feature_X[test_idx]\n",
    "            y_test = feature_y[test_idx].astype(int)\n",
    "            y_true = y_test\n",
    "\n",
    "            if ENABLE_FEATURE_SELECTION == 1:\n",
    "                X_train, X_test, scaler, selector = fit_transform_selector(\n",
    "                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=FEATURE_K\n",
    "                )\n",
    "            else:\n",
    "                X_train, X_test, scaler, selector = fit_transform_selector(\n",
    "                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=0\n",
    "                )\n",
    "\n",
    "            clf = LogisticRegression(\n",
    "                max_iter=5000,\n",
    "                class_weight=\"balanced\",\n",
    "                solver=\"lbfgs\",\n",
    "                random_state=run,\n",
    "                n_jobs=None\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            pred_raw = clf.predict(X_test).astype(int)\n",
    "            acc_raw = accuracy_score(y_true, pred_raw)\n",
    "\n",
    "            pred_smooth = None\n",
    "            acc_smooth = np.nan\n",
    "            if ENABLE_POSTPROCESSING == 1:\n",
    "                pred_smooth = smooth_predictions(pred_raw, window=SMOOTH_WINDOW).astype(int)\n",
    "                acc_smooth = accuracy_score(y_true, pred_smooth)\n",
    "\n",
    "        # confusion matrices for reporting\n",
    "        cm_raw = confusion_matrix(y_true, pred_raw, labels=[0, 1]).ravel()\n",
    "        if cm_raw.size == 4:\n",
    "            tn_raw, fp_raw, fn_raw, tp_raw = cm_raw\n",
    "        else:\n",
    "            tn_raw = fp_raw = fn_raw = tp_raw = 0\n",
    "\n",
    "        if ENABLE_POSTPROCESSING == 1 and pred_smooth is not None:\n",
    "            cm_s = confusion_matrix(y_true, pred_smooth, labels=[0, 1]).ravel()\n",
    "            if cm_s.size == 4:\n",
    "                tn_s, fp_s, fn_s, tp_s = cm_s\n",
    "            else:\n",
    "                tn_s = fp_s = fn_s = tp_s = 0\n",
    "        else:\n",
    "            tn_s = fp_s = fn_s = tp_s = np.nan\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"run\": run + 1,\n",
    "            \"subject\": test_subj,\n",
    "            \"n_samples\": int(len(y_true)),\n",
    "            \"acc_raw\": float(acc_raw),\n",
    "            \"acc_smooth\": float(acc_smooth) if ENABLE_POSTPROCESSING == 1 else np.nan,\n",
    "            \"tn_raw\": int(tn_raw), \"fp_raw\": int(fp_raw), \"fn_raw\": int(fn_raw), \"tp_raw\": int(tp_raw),\n",
    "            \"tn_smooth\": float(tn_s), \"fp_smooth\": float(fp_s), \"fn_smooth\": float(fn_s), \"tp_smooth\": float(tp_s),\n",
    "        })\n",
    "\n",
    "        all_results_raw[run, test_subj - 1] = acc_raw\n",
    "        if ENABLE_POSTPROCESSING == 1:\n",
    "            all_results_smooth[run, test_subj - 1] = acc_smooth\n",
    "\n",
    "        stored_predictions[(run + 1, test_subj)] = {\n",
    "            \"y_true\": y_true,\n",
    "            \"pred_raw\": pred_raw,\n",
    "            \"pred_smooth\": pred_smooth if ENABLE_POSTPROCESSING == 1 else None,\n",
    "        }\n",
    "\n",
    "        if ENABLE_POSTPROCESSING == 1:\n",
    "            print(f\"  Subject {test_subj:2d}: raw={acc_raw:.4f} | smooth={acc_smooth:.4f}\")\n",
    "        else:\n",
    "            print(f\"  Subject {test_subj:2d}: {acc_raw:.4f}\")\n",
    "\n",
    "    print(f\"Run mean (raw): {np.mean(all_results_raw[run]):.4f}\")\n",
    "    if ENABLE_POSTPROCESSING == 1:\n",
    "        print(f\"Run mean (smooth): {np.nanmean(all_results_smooth[run]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1d440",
   "metadata": {
    "papermill": {
     "duration": 0.02103,
     "end_time": "2026-01-03T19:57:38.882027",
     "exception": false,
     "start_time": "2026-01-03T19:57:38.860997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 5 — Post-processing\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f8c185c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:57:38.936100Z",
     "iopub.status.busy": "2026-01-03T19:57:38.934505Z",
     "iopub.status.idle": "2026-01-03T19:57:38.946816Z",
     "shell.execute_reply": "2026-01-03T19:57:38.946206Z"
    },
    "papermill": {
     "duration": 0.042178,
     "end_time": "2026-01-03T19:57:38.948339",
     "exception": false,
     "start_time": "2026-01-03T19:57:38.906161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def smooth_predictions(pred, window=5):\n",
    "    pred = np.asarray(pred).astype(int)\n",
    "    if window is None or window <= 1:\n",
    "        return pred\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "\n",
    "    pad = window // 2\n",
    "    padded = np.pad(pred, (pad, pad), mode=\"edge\")\n",
    "    out = pred.copy()\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        w = padded[i:i + window]\n",
    "        out[i] = 1 if np.mean(w) >= 0.5 else 0\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a8646",
   "metadata": {
    "papermill": {
     "duration": 0.006805,
     "end_time": "2026-01-03T19:57:38.962603",
     "exception": false,
     "start_time": "2026-01-03T19:57:38.955798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 6 — Evaluation\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e58d155d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T19:57:38.977639Z",
     "iopub.status.busy": "2026-01-03T19:57:38.977383Z",
     "iopub.status.idle": "2026-01-03T19:57:39.461691Z",
     "shell.execute_reply": "2026-01-03T19:57:39.460842Z"
    },
    "papermill": {
     "duration": 0.493495,
     "end_time": "2026-01-03T19:57:39.463107",
     "exception": false,
     "start_time": "2026-01-03T19:57:38.969612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall mean (raw): 0.6523640782053125\n",
      "Overall std  (raw): 0.1309273962846851\n",
      "Overall mean (post-processed): 0.671701176539106\n",
      "Overall std  (post-processed): 0.1491\n",
      "\n",
      "✓ Results saved\n",
      "✓ Excel saved: نتایج_نهایی.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"\\nOverall mean (raw):\", np.mean(all_results_raw))\n",
    "print(\"Overall std  (raw):\", np.std(all_results_raw))\n",
    "\n",
    "if ENABLE_POSTPROCESSING == 1:\n",
    "    print(\"Overall mean (post-processed):\", np.nanmean(all_results_smooth))\n",
    "    print(f\"Overall std  (post-processed): {np.nanstd(all_results_smooth):.4f}\")\n",
    "\n",
    "# Save numpy results\n",
    "np.save(\"results_raw.npy\", all_results_raw)\n",
    "if ENABLE_POSTPROCESSING == 1:\n",
    "    np.save(\"results_smooth.npy\", all_results_smooth)\n",
    "\n",
    "# Build Excel tables\n",
    "fold_df = pd.DataFrame(fold_rows)\n",
    "\n",
    "# Per-subject summary\n",
    "summary_cols = [\"acc_raw\"]\n",
    "if ENABLE_POSTPROCESSING == 1:\n",
    "    summary_cols.append(\"acc_smooth\")\n",
    "\n",
    "subj_summary = (\n",
    "    fold_df.groupby(\"subject\")[summary_cols]\n",
    "    .agg([\"mean\", \"std\", \"count\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten multi-index columns for Excel readability\n",
    "subj_summary.columns = [\"_\".join([c for c in col if c]) for col in subj_summary.columns.values]\n",
    "\n",
    "# Overall summary\n",
    "overall = {}\n",
    "overall[\"metric\"] = \"raw\"\n",
    "overall[\"mean\"] = float(np.mean(all_results_raw))\n",
    "overall[\"std\"] = float(np.std(all_results_raw))\n",
    "overall_rows = [overall]\n",
    "\n",
    "if ENABLE_POSTPROCESSING == 1:\n",
    "    overall_rows.append({\n",
    "        \"metric\": \"smooth\",\n",
    "        \"mean\": float(np.nanmean(all_results_smooth)),\n",
    "        \"std\": float(np.nanstd(all_results_smooth)),\n",
    "    })\n",
    "\n",
    "overall_df = pd.DataFrame(overall_rows)\n",
    "\n",
    "excel_path = \"نتایج_نهایی.xlsx\"\n",
    "with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "    fold_df.to_excel(writer, index=False, sheet_name=\"folds\")\n",
    "    subj_summary.to_excel(writer, index=False, sheet_name=\"per_subject\")\n",
    "    overall_df.to_excel(writer, index=False, sheet_name=\"overall\")\n",
    "\n",
    "print(\"\\n✓ Results saved\")\n",
    "print(f\"✓ Excel saved: {excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c906aa7",
   "metadata": {
    "papermill": {
     "duration": 0.006789,
     "end_time": "2026-01-03T19:57:39.477094",
     "exception": false,
     "start_time": "2026-01-03T19:57:39.470305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9173680,
     "sourceId": 14366015,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9173706,
     "sourceId": 14366056,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.576955,
   "end_time": "2026-01-03T19:57:41.507028",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-03T19:51:24.930073",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
