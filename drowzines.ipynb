{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14366015,"sourceType":"datasetVersion","datasetId":9173680},{"sourceId":14366056,"sourceType":"datasetVersion","datasetId":9173706}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":21401.524061,"end_time":"2026-01-02T12:28:36.564078","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2026-01-02T06:31:55.040017","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"14d8de9d-0ac6-404a-a205-ed1ed378d522","cell_type":"markdown","source":"---\nCell 0 — Pipeline Switches (0/1)\n---\n---","metadata":{}},{"id":"a64e951e-fdd4-42b5-b159-a4c39b12dd15","cell_type":"code","source":"# Pipeline mode:\n# 0 = CNN on time-series (your current Torch training)\n# 1 = Feature-based ML (Logistic Regression with optional feature selection + postprocess)\nPIPELINE_MODE = 1\n\n# Section switches (0/1)\nENABLE_FEATURE_EXTRACTION = 1\nENABLE_FEATURE_SELECTION = 1\nENABLE_POSTPROCESSING = 1\n\n# Recommended presets:\n# - CNN pipeline: PIPELINE_MODE=0, ENABLE_FEATURE_EXTRACTION=0, ENABLE_FEATURE_SELECTION=0\n# - Feature pipeline: PIPELINE_MODE=1, ENABLE_FEATURE_EXTRACTION=1, ENABLE_FEATURE_SELECTION=1\n\n# Feature extraction settings (used when ENABLE_FEATURE_EXTRACTION=1)\nFS = 128.0  # sampling rate (Hz). Change if your dataset uses a different FS.\n\nBANDS = {\n    \"delta\": (0.5, 4.0),\n    \"theta\": (4.0, 8.0),\n    \"alpha\": (8.0, 13.0),\n    \"beta\":  (13.0, 30.0),\n    \"gamma\": (30.0, 45.0),\n}\n\n# Feature selection settings (used when ENABLE_FEATURE_SELECTION=1)\nFEATURE_SELECTION_METHOD = \"f_classif\"  # \"f_classif\" or \"mutual_info\"\nFEATURE_K = 200  # number of selected features (top-K)\n\n# Post-processing settings (used when ENABLE_POSTPROCESSING=1)\nSMOOTH_WINDOW = 5  # odd integer recommended (e.g., 3,5,7)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:12:18.860908Z","iopub.execute_input":"2026-01-02T21:12:18.861607Z","iopub.status.idle":"2026-01-02T21:12:18.866228Z","shell.execute_reply.started":"2026-01-02T21:12:18.861576Z","shell.execute_reply":"2026-01-02T21:12:18.865547Z"}},"outputs":[],"execution_count":10},{"id":"710911e0-460f-46af-853e-2240b714f50e","cell_type":"markdown","source":"---\nCell 1 — Preprocessing\n---\n---","metadata":{}},{"id":"46954b63","cell_type":"code","source":"!pip install -q torch scipy scikit-learn\nprint(\"✓ Installation completed\")\n\n# Copy dataset\n!cp \"/kaggle/input/dataset-drowsiness/dataset (1).mat\" /kaggle/working/dataset.mat\n\n# Check\n!ls -lh /kaggle/working/\nprint(\"\\n✓ Dataset copied\")\n\nimport os\nos.environ['TORCH_COMPILE_DISABLE'] = '1'\nos.environ['TORCHDYNAMO_DISABLE'] = '1'\n\nimport torch\ntorch._dynamo.config.suppress_errors = True\n\nimport torch.nn as nn\nimport torch.optim as optim\nimport scipy.io as sio\nimport numpy as np\nimport scipy.stats as stats\nfrom sklearn.metrics import accuracy_score\n\n\n# Electrode indices\nfp1, fp2, f7 = 0, 1, 2\nf3, fz, f4 = 3, 4, 5\nf8, ft7, fc3 = 6, 7, 8\nfcz, fc4, ft8 = 9, 10, 11\nt3, c3, cz = 12, 13, 14\nc4, t4, tp7 = 15, 16, 17\ncp3, cpz, cp4 = 18, 19, 20\ntp8a1, t5, p3 = 21, 22, 23\npz, p4, t6a2 = 24, 25, 26\no1, oz, o2 = 27, 28, 29\n\n# Subject boundaries (original sample indices)\nstartsub = np.zeros(11)\nfinalsub = np.zeros(11)\nstartsub[0] = 0\nfinalsub[0] = 188\nstartsub[1] = finalsub[0]\nfinalsub[1] = 320\nstartsub[2] = finalsub[1]\nfinalsub[2] = 470\nstartsub[3] = finalsub[2]\nfinalsub[3] = 618\nstartsub[4] = finalsub[3]\nfinalsub[4] = 842\nstartsub[5] = finalsub[4]\nfinalsub[5] = 1008\nstartsub[6] = finalsub[5]\nfinalsub[6] = 1110\nstartsub[7] = finalsub[6]\nfinalsub[7] = 1374\nstartsub[8] = finalsub[7]\nfinalsub[8] = 1688\nstartsub[9] = finalsub[8]\nfinalsub[9] = 1796\nstartsub[10] = finalsub[9]\nfinalsub[10] = 2022\n\n\ndef bipolar(xdata):\n    xdatabipolar = np.zeros((2022, 32, 384))\n    # vertical\n    # 1\n    xdatabipolar[:, 0, :] = xdata[:, fp1, :] - xdata[:, f7, :]\n    xdatabipolar[:, 1, :] = xdata[:, f7, :] - xdata[:, t3, :]\n    xdatabipolar[:, 2, :] = xdata[:, t3, :] - xdata[:, t5, :]\n    xdatabipolar[:, 3, :] = xdata[:, t5, :] - xdata[:, o1, :]\n    xdatabipolar[:, 4, :] = xdata[:, o1, :] - xdata[:, p3, :]\n    xdatabipolar[:, 5, :] = xdata[:, p3, :] - xdata[:, c3, :]\n    xdatabipolar[:, 6, :] = xdata[:, c3, :] - xdata[:, f3, :]\n    xdatabipolar[:, 7, :] = xdata[:, f3, :] - xdata[:, fp1, :]\n    # 2\n    xdatabipolar[:, 8, :] = xdata[:, pz, :] - xdata[:, cz, :]\n    xdatabipolar[:, 9, :] = xdata[:, cz, :] - xdata[:, fz, :]\n    # 3\n    xdatabipolar[:, 10, :] = xdata[:, fp2, :] - xdata[:, f8, :]\n    xdatabipolar[:, 11, :] = xdata[:, f8, :] - xdata[:, t4, :]\n    xdatabipolar[:, 12, :] = xdata[:, t4, :] - xdata[:, t6a2, :]\n    xdatabipolar[:, 13, :] = xdata[:, t6a2, :] - xdata[:, o2, :]\n    xdatabipolar[:, 14, :] = xdata[:, o2, :] - xdata[:, p4, :]\n    xdatabipolar[:, 15, :] = xdata[:, p4, :] - xdata[:, c4, :]\n    xdatabipolar[:, 16, :] = xdata[:, c4, :] - xdata[:, f4, :]\n    xdatabipolar[:, 17, :] = xdata[:, f4, :] - xdata[:, fp2, :]\n    # horizontal\n    # 4\n    xdatabipolar[:, 18, :] = xdata[:, fp1, :] - xdata[:, fp2, :]\n    xdatabipolar[:, 19, :] = xdata[:, f8, :] - xdata[:, f4, :]\n    xdatabipolar[:, 20, :] = xdata[:, f4, :] - xdata[:, fz, :]\n    xdatabipolar[:, 21, :] = xdata[:, fz, :] - xdata[:, f3, :]\n    xdatabipolar[:, 22, :] = xdata[:, f3, :] - xdata[:, f7, :]\n    # 5\n    xdatabipolar[:, 23, :] = xdata[:, t3, :] - xdata[:, c3, :]\n    xdatabipolar[:, 24, :] = xdata[:, c3, :] - xdata[:, cz, :]\n    xdatabipolar[:, 25, :] = xdata[:, cz, :] - xdata[:, c4, :]\n    xdatabipolar[:, 26, :] = xdata[:, c4, :] - xdata[:, t4, :]\n    # 6\n    xdatabipolar[:, 27, :] = xdata[:, t5, :] - xdata[:, p3, :]\n    xdatabipolar[:, 28, :] = xdata[:, p3, :] - xdata[:, pz, :]\n    xdatabipolar[:, 29, :] = xdata[:, pz, :] - xdata[:, p4, :]\n    xdatabipolar[:, 30, :] = xdata[:, p4, :] - xdata[:, t6a2, :]\n    xdatabipolar[:, 31, :] = xdata[:, o2, :] - xdata[:, o1, :]\n    return xdatabipolar\n\n\ndef zscoresubjective(xdatabipolar):\n    startsub = np.zeros(11)\n    finalsub = np.zeros(11)\n    startsub[0] = 0\n    finalsub[0] = 188 * 3 - 2\n    startsub[1] = finalsub[0]\n    finalsub[1] = 320 * 3 - 2\n    startsub[2] = finalsub[1]\n    finalsub[2] = 470 * 3 - 2\n    startsub[3] = finalsub[2]\n    finalsub[3] = 618 * 3 - 2\n    startsub[4] = finalsub[3]\n    finalsub[4] = 842 * 3 - 2\n    startsub[5] = finalsub[4]\n    finalsub[5] = 1008 * 3 - 2\n    startsub[6] = finalsub[5]\n    finalsub[6] = 1110 * 3 - 2\n    startsub[7] = finalsub[6]\n    finalsub[7] = 1374 * 3 - 2\n    startsub[8] = finalsub[7]\n    finalsub[8] = 1688 * 3 - 2\n    startsub[9] = finalsub[8]\n    finalsub[9] = 1796 * 3 - 2\n    startsub[10] = finalsub[9]\n    finalsub[10] = 2022 * 3 - 2\n\n    for i in range(0, 11):\n        xdatabipolar[int(startsub[i]):int(finalsub[i])] = stats.zscore(\n            xdatabipolar[int(startsub[i]):int(finalsub[i])]\n        )\n    return xdatabipolar\n\n\ndef hamposhanisub(xdata, label, ncha):\n    n = len(xdata)\n    k = 3 * n - 2\n    newdata = np.zeros((k, ncha, 384))\n    newlabel = np.zeros((k))\n    leni1 = 0\n    for iindex in range(11):\n        s = startsub[iindex]\n        f = finalsub[iindex]\n        leni2 = leni1 + int(f - s)\n        for i in range(leni1, leni2 - 1):\n            newdata[(3 * i), :, :] = xdata[i, :, :]\n\n            newdata[(3 * i) + 1, :, :256] = xdata[i, :, 128:]\n            newdata[(3 * i) + 1, :, 256:] = xdata[i + 1, :, :128]\n\n            newdata[(3 * i) + 2, :, :128] = xdata[i, :, 256:]\n            newdata[(3 * i) + 2, :, 128:] = xdata[i + 1, :, :256]\n\n        for i in range(leni1, leni2 - 1):\n            newlabel[(3 * i)] = label[i]\n            newlabel[(3 * i) + 1] = label[i]\n            newlabel[(3 * i) + 2] = label[i + 1]\n        leni1 = leni2\n\n    startsub[0] = 0\n    finalsub[0] = 188 * 3 - 2\n    startsub[1] = finalsub[0]\n    finalsub[1] = 320 * 3 - 2\n    startsub[2] = finalsub[1]\n    finalsub[2] = 470 * 3 - 2\n    startsub[3] = finalsub[2]\n    finalsub[3] = 618 * 3 - 2\n    startsub[4] = finalsub[3]\n    finalsub[4] = 842 * 3 - 2\n    startsub[5] = finalsub[4]\n    finalsub[5] = 1008 * 3 - 2\n    startsub[6] = finalsub[5]\n    finalsub[6] = 1110 * 3 - 2\n    startsub[7] = finalsub[6]\n    finalsub[7] = 1374 * 3 - 2\n    startsub[8] = finalsub[7]\n    finalsub[8] = 1688 * 3 - 2\n    startsub[9] = finalsub[8]\n    finalsub[9] = 1796 * 3 - 2\n    startsub[10] = finalsub[9]\n    finalsub[10] = 2022 * 3 - 2\n\n    return newdata, newlabel, finalsub, startsub\n\n\nAPPLY_BIPOLAR = True\nAPPLY_OVERLAP = True\nAPPLY_ZSCORE = True\n\nN_RUNS = 2\nN_EPOCHS = 11\nBATCH_SIZE = 50\nLEARNING_RATE = 0.001\nDATASET_PATH = 'dataset.mat'\n\nprint(\"=\" * 70)\nprint(\"Settings:\")\nprint(f\"  Bipolar: {APPLY_BIPOLAR}\")\nprint(f\"  Overlap: {APPLY_OVERLAP}\")\nprint(f\"  Z-score: {APPLY_ZSCORE}\")\nprint(f\"  Runs: {N_RUNS}\")\nprint(f\"  Epochs: {N_EPOCHS}\")\nprint(\"=\" * 70)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"\\nUsing device: {device}\")\n\nprint(\"\\n[1] Loading dataset...\")\ndata = sio.loadmat(DATASET_PATH)\noriginal_data = np.array(data['EEGsample'])\noriginal_labels = np.array(data['substate']).flatten().astype(int)\nprint(f\"✓ Shape: {original_data.shape}\")\n\ndef create_subject_index():\n    subIdx = np.zeros(2022, dtype=int)\n    boundaries = [0, 188, 320, 470, 618, 842, 1008, 1110, 1374, 1688, 1796, 2022]\n    for i in range(11):\n        subIdx[boundaries[i]:boundaries[i + 1]] = i + 1\n    return subIdx\n\nprint(\"\\n[2] Preprocessing...\")\nprocessed_data = original_data.copy()\nprocessed_labels = original_labels.copy()\nsubIdx = create_subject_index()\nn_channels = 30\n\nif APPLY_BIPOLAR:\n    print(\"  -> Applying bipolar montage...\")\n    processed_data = bipolar(processed_data)\n    n_channels = 32\n    print(f\"    Channels: {original_data.shape[1]} -> {n_channels}\")\n\nif APPLY_OVERLAP:\n    print(\"  -> Applying overlap augmentation...\")\n    before = processed_data.shape[0]\n    processed_data, processed_labels, finalsub_aug, startsub_aug = hamposhanisub(\n        processed_data, processed_labels, n_channels\n    )\n    print(f\"    Samples: {before} -> {processed_data.shape[0]}\")\n\n    new_subIdx = np.zeros(processed_data.shape[0], dtype=int)\n    idx = 0\n    for subj in range(11):\n        n_augmented = int(finalsub_aug[subj] - (startsub_aug[subj] if subj == 0 else finalsub_aug[subj - 1]))\n        new_subIdx[idx:idx + n_augmented] = subj + 1\n        idx += n_augmented\n    subIdx = new_subIdx\n\nif APPLY_ZSCORE:\n    print(\"  -> Applying subject-wise z-score normalization...\")\n    processed_data = zscoresubjective(processed_data)\n    print(f\"    Mean: {np.mean(processed_data):.4f}\")\n\nprint(f\"✓ Final shape: {processed_data.shape}\")\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-02T21:12:18.867455Z","iopub.execute_input":"2026-01-02T21:12:18.867672Z","iopub.status.idle":"2026-01-02T21:12:26.210279Z","shell.execute_reply.started":"2026-01-02T21:12:18.867644Z","shell.execute_reply":"2026-01-02T21:12:26.209490Z"},"papermill":{"duration":4.053317,"end_time":"2026-01-02T06:32:01.491169","exception":false,"start_time":"2026-01-02T06:31:57.437852","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"✓ Installation completed\ntotal 173M\n-rw-r--r-- 1 root root 173M Jan  2 21:12 dataset.mat\n-rw-r--r-- 1 root root  216 Jan  2 21:12 results_final.npy\n\n✓ Dataset copied\n======================================================================\nSettings:\n  Bipolar: True\n  Overlap: True\n  Z-score: True\n  Runs: 2\n  Epochs: 11\n======================================================================\n\nUsing device: cuda\n\n[1] Loading dataset...\n✓ Shape: (2022, 30, 384)\n\n[2] Preprocessing...\n  -> Applying bipolar montage...\n    Channels: 30 -> 32\n  -> Applying overlap augmentation...\n    Samples: 2022 -> 6064\n  -> Applying subject-wise z-score normalization...\n    Mean: 0.0000\n✓ Final shape: (6064, 32, 384)\n","output_type":"stream"}],"execution_count":11},{"id":"164a6b96-4316-416a-8637-0cb9c700263d","cell_type":"markdown","source":"---\nCell 2 — Feature Extraction\n---\n---","metadata":{}},{"id":"97bfdc10-0a2d-44ec-9f94-04d2bc18b955","cell_type":"code","source":"def _bandpower_from_psd(freqs, psd, fmin, fmax):\n    mask = (freqs >= fmin) & (freqs < fmax)\n    if not np.any(mask):\n        return 0.0\n    return np.trapz(psd[mask], freqs[mask])\n\ndef _hjorth_params(x):\n    x = np.asarray(x)\n    dx = np.diff(x)\n    ddx = np.diff(dx)\n    var_x = np.var(x) + 1e-12\n    var_dx = np.var(dx) + 1e-12\n    var_ddx = np.var(ddx) + 1e-12\n    activity = var_x\n    mobility = np.sqrt(var_dx / var_x)\n    complexity = np.sqrt(var_ddx / var_dx) / (mobility + 1e-12)\n    return activity, mobility, complexity\n\ndef extract_eeg_features(X, fs, bands):\n    # X: (N, C, T)\n    N, C, T = X.shape\n    freqs = np.fft.rfftfreq(T, d=1.0 / fs)\n    feats = []\n\n    for i in range(N):\n        sample_feats = []\n        for ch in range(C):\n            x = X[i, ch, :]\n            x = x - np.mean(x)\n\n            fft = np.fft.rfft(x)\n            psd = (np.abs(fft) ** 2) / (T + 1e-12)\n\n            band_powers = {}\n            total_power = _bandpower_from_psd(freqs, psd, 0.5, 45.0) + 1e-12\n            for name, (fmin, fmax) in bands.items():\n                bp = _bandpower_from_psd(freqs, psd, fmin, fmax)\n                band_powers[name] = bp\n\n            # Relative bandpowers\n            rel = [band_powers[k] / total_power for k in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]]\n\n            # Ratios often useful for drowsiness\n            theta_alpha = band_powers[\"theta\"] / (band_powers[\"alpha\"] + 1e-12)\n            theta_beta = band_powers[\"theta\"] / (band_powers[\"beta\"] + 1e-12)\n            (act, mob, comp) = _hjorth_params(x)\n\n            # Spectral entropy (0..1)\n            p = psd / (np.sum(psd) + 1e-12)\n            spec_entropy = -np.sum(p * np.log(p + 1e-12)) / (np.log(len(p)) + 1e-12)\n\n            sample_feats.extend(rel)\n            sample_feats.extend([theta_alpha, theta_beta])\n            sample_feats.extend([act, mob, comp])\n            sample_feats.append(spec_entropy)\n\n        feats.append(sample_feats)\n\n    return np.asarray(feats, dtype=np.float64)\n\nfeature_X = None\nfeature_y = None\nfeature_groups = None\n\nif ENABLE_FEATURE_EXTRACTION == 1:\n    print(\"[Feature Extraction] Computing EEG features...\")\n    feature_X = extract_eeg_features(processed_data, FS, BANDS)\n    feature_y = processed_labels.astype(int).copy()\n    feature_groups = subIdx.astype(int).copy()\n    print(f\"[Feature Extraction] feature_X shape: {feature_X.shape}\")\nelse:\n    print(\"[Feature Extraction] Disabled\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:12:26.212057Z","iopub.execute_input":"2026-01-02T21:12:26.212319Z","iopub.status.idle":"2026-01-02T21:13:28.313952Z","shell.execute_reply.started":"2026-01-02T21:12:26.212291Z","shell.execute_reply":"2026-01-02T21:13:28.313192Z"}},"outputs":[{"name":"stdout","text":"[Feature Extraction] Computing EEG features...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/1758092842.py:5: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n  return np.trapz(psd[mask], freqs[mask])\n","output_type":"stream"},{"name":"stdout","text":"[Feature Extraction] feature_X shape: (6064, 352)\n","output_type":"stream"}],"execution_count":12},{"id":"a84199e6-df03-4892-a11b-cdf881cd0354","cell_type":"markdown","source":"---\nCell 3 — Feature Selection\n---\n---","metadata":{}},{"id":"b02c1a35-d127-4a6d-ab8b-b5fe74c08157","cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n\ndef fit_transform_selector(X_train, y_train, X_test, method=\"f_classif\", k=200):\n    scaler = StandardScaler()\n    X_train_s = scaler.fit_transform(X_train)\n    X_test_s = scaler.transform(X_test)\n\n    if k is None or k <= 0 or k >= X_train_s.shape[1]:\n        return X_train_s, X_test_s, scaler, None\n\n    if method == \"mutual_info\":\n        selector = SelectKBest(mutual_info_classif, k=k)\n    else:\n        selector = SelectKBest(f_classif, k=k)\n\n    X_train_sel = selector.fit_transform(X_train_s, y_train)\n    X_test_sel = selector.transform(X_test_s)\n    return X_train_sel, X_test_sel, scaler, selector\n\nprint(\"[Feature Selection] Ready (applied inside training loop if enabled)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:13:28.315095Z","iopub.execute_input":"2026-01-02T21:13:28.315348Z","iopub.status.idle":"2026-01-02T21:13:28.321218Z","shell.execute_reply.started":"2026-01-02T21:13:28.315325Z","shell.execute_reply":"2026-01-02T21:13:28.320506Z"}},"outputs":[{"name":"stdout","text":"[Feature Selection] Ready (applied inside training loop if enabled)\n","output_type":"stream"}],"execution_count":13},{"id":"b03f39b1-00d6-4692-8ad1-2519ca9d2a5d","cell_type":"markdown","source":"---\nCell 4 — Model Training\n---\n---","metadata":{}},{"id":"03b0be48-5a0d-4fa5-809f-6a78ad50e223","cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclass InterpretableCNN(nn.Module):\n    def __init__(self, n_channels=30):\n        super().__init__()\n        self.temp_conv = nn.Conv2d(1, 40, (1, 64), bias=False)\n        self.spat_conv = nn.Conv2d(40, 40, (n_channels, 1), bias=False)\n        self.bn = nn.BatchNorm2d(40, track_running_stats=False)\n        self.pool = nn.AvgPool2d((1, 8))\n        self.fc = nn.Linear(40 * ((384 - 64 + 1) // 8), 2)\n        self.log_softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.temp_conv(x)\n        x = self.spat_conv(x)\n        x = self.bn(x)\n        x = torch.square(x)\n        x = self.pool(x)\n        x = torch.log(torch.clamp(x, min=1e-6))\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return self.log_softmax(x)\n\n\nprint(f\"[Training] PIPELINE_MODE={PIPELINE_MODE}\")\nall_results = np.zeros((N_RUNS, 11))\n\nfor run in range(N_RUNS):\n    print(f\"\\n{'=' * 70}\")\n    print(f\"Run {run + 1}/{N_RUNS}\")\n    print(f\"{'=' * 70}\")\n\n    torch.manual_seed(run)\n    np.random.seed(run)\n\n    for test_subj in range(1, 12):\n        train_mask = (subIdx != test_subj)\n        test_mask = (subIdx == test_subj)\n\n        if PIPELINE_MODE == 0:\n            # CNN on time-series\n            x_train = processed_data[train_mask].reshape(-1, 1, n_channels, 384)\n            y_train = processed_labels[train_mask].astype(np.longlong)\n            x_test = processed_data[test_mask].reshape(-1, 1, n_channels, 384)\n            y_test = processed_labels[test_mask].astype(np.longlong)\n\n            train_dataset = torch.utils.data.TensorDataset(\n                torch.from_numpy(x_train), torch.from_numpy(y_train)\n            )\n            train_loader = torch.utils.data.DataLoader(\n                train_dataset, batch_size=BATCH_SIZE, shuffle=True\n            )\n\n            model = InterpretableCNN(n_channels=n_channels).double().to(device)\n            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n            criterion = nn.NLLLoss()\n\n            model.train()\n            for epoch in range(N_EPOCHS):\n                for batch_x, batch_y in train_loader:\n                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n                    optimizer.zero_grad()\n                    output = model(batch_x)\n                    loss = criterion(output, batch_y)\n                    loss.backward()\n                    optimizer.step()\n\n            model.eval()\n            with torch.no_grad():\n                x_test_t = torch.DoubleTensor(x_test).to(device)\n                pred = model(x_test_t).cpu().numpy().argmax(axis=1)\n                acc = accuracy_score(y_test, pred)\n\n            all_results[run, test_subj - 1] = acc\n            print(f\"  Subject {test_subj:2d}: {acc:.4f}\")\n\n            del model\n            if torch.cuda.is_available():\n                torch.cuda.empty_cache()\n\n        else:\n            # Feature-based ML\n            if feature_X is None or feature_y is None or feature_groups is None:\n                raise RuntimeError(\"Feature extraction is required for PIPELINE_MODE=1. Set ENABLE_FEATURE_EXTRACTION=1.\")\n\n            X_train = feature_X[train_mask]\n            y_train = feature_y[train_mask]\n            X_test = feature_X[test_mask]\n            y_test = feature_y[test_mask]\n\n            if ENABLE_FEATURE_SELECTION == 1:\n                X_train, X_test, scaler, selector = fit_transform_selector(\n                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=FEATURE_K\n                )\n            else:\n                X_train, X_test, scaler, selector = fit_transform_selector(\n                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=0\n                )\n\n            clf = LogisticRegression(\n                max_iter=2000,\n                class_weight=\"balanced\",\n                random_state=run,\n                n_jobs=None\n            )\n            clf.fit(X_train, y_train)\n            pred = clf.predict(X_test)\n            acc = accuracy_score(y_test, pred)\n\n            all_results[run, test_subj - 1] = acc\n            print(f\"  Subject {test_subj:2d}: {acc:.4f}\")\n\n    print(f\"Run mean: {np.mean(all_results[run]):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:13:28.322898Z","iopub.execute_input":"2026-01-02T21:13:28.323165Z","iopub.status.idle":"2026-01-02T21:14:00.452906Z","shell.execute_reply.started":"2026-01-02T21:13:28.323144Z","shell.execute_reply":"2026-01-02T21:14:00.452179Z"}},"outputs":[{"name":"stdout","text":"[Training] PIPELINE_MODE=1\n\n======================================================================\nRun 1/2\n======================================================================\n  Subject  1: 0.7242\n  Subject  2: 0.8813\n  Subject  3: 0.7111\n  Subject  4: 0.6486\n  Subject  5: 0.8214\n  Subject  6: 0.7851\n  Subject  7: 0.5980\n  Subject  8: 0.6957\n  Subject  9: 0.8652\n  Subject 10: 0.9043\n  Subject 11: 0.7227\nRun mean: 0.7598\n\n======================================================================\nRun 2/2\n======================================================================\n  Subject  1: 0.7242\n  Subject  2: 0.8813\n  Subject  3: 0.7111\n  Subject  4: 0.6486\n  Subject  5: 0.8214\n  Subject  6: 0.7851\n  Subject  7: 0.5980\n  Subject  8: 0.6957\n  Subject  9: 0.8652\n  Subject 10: 0.9043\n  Subject 11: 0.7227\nRun mean: 0.7598\n","output_type":"stream"}],"execution_count":14},{"id":"09fb298d-0019-4c22-8839-af540f18f201","cell_type":"markdown","source":"---\nCell 5 — Post-processing\n---\n---","metadata":{}},{"id":"88274e13-e155-48a1-9015-0ab019ef4829","cell_type":"code","source":"def smooth_predictions(pred, window=5):\n    pred = np.asarray(pred).astype(int)\n    if window is None or window <= 1:\n        return pred\n    if window % 2 == 0:\n        window += 1\n\n    pad = window // 2\n    padded = np.pad(pred, (pad, pad), mode=\"edge\")\n    out = pred.copy()\n\n    for i in range(len(pred)):\n        w = padded[i:i + window]\n        out[i] = 1 if np.mean(w) >= 0.5 else 0\n    return out\n\nprint(\"[Post-processing] Ready (apply in evaluation if enabled)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:14:00.454419Z","iopub.execute_input":"2026-01-02T21:14:00.454704Z","iopub.status.idle":"2026-01-02T21:14:00.469042Z","shell.execute_reply.started":"2026-01-02T21:14:00.454676Z","shell.execute_reply":"2026-01-02T21:14:00.467347Z"}},"outputs":[{"name":"stdout","text":"[Post-processing] Ready (apply in evaluation if enabled)\n","output_type":"stream"}],"execution_count":15},{"id":"1f39b571-2def-4aee-af31-a07c3bf0a4e9","cell_type":"markdown","source":"---\nCell 6 — Evaluation\n---\n---","metadata":{}},{"id":"606791c9-efbb-448f-b80a-e0d3f684e3b5","cell_type":"code","source":"# Optional: apply post-processing to stored results would require keeping per-subject predictions.\n# This cell provides final reporting for the current pipeline outputs (accuracy per subject).\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"Final Results\")\nprint(\"=\" * 70)\n\nprint(\"\\nAccuracy per Subject:\")\nfor i in range(11):\n    mean = np.mean(all_results[:, i])\n    std = np.std(all_results[:, i])\n    print(f\"  Subject {i + 1:2d}: {mean:.4f} ± {std:.4f}\")\n\nprint(f\"\\nOverall mean: {np.mean(all_results):.4f}\")\nprint(f\"Overall std:  {np.std(all_results):.4f}\")\n\nnp.save(\"results_final.npy\", all_results)\nprint(\"\\n✓ Results saved\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T21:14:00.469769Z","iopub.execute_input":"2026-01-02T21:14:00.470505Z","iopub.status.idle":"2026-01-02T21:14:00.489214Z","shell.execute_reply.started":"2026-01-02T21:14:00.470472Z","shell.execute_reply":"2026-01-02T21:14:00.487909Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nFinal Results\n======================================================================\n\nAccuracy per Subject:\n  Subject  1: 0.7242 ± 0.0000\n  Subject  2: 0.8813 ± 0.0000\n  Subject  3: 0.7111 ± 0.0000\n  Subject  4: 0.6486 ± 0.0000\n  Subject  5: 0.8214 ± 0.0000\n  Subject  6: 0.7851 ± 0.0000\n  Subject  7: 0.5980 ± 0.0000\n  Subject  8: 0.6957 ± 0.0000\n  Subject  9: 0.8652 ± 0.0000\n  Subject 10: 0.9043 ± 0.0000\n  Subject 11: 0.7227 ± 0.0000\n\nOverall mean: 0.7598\nOverall std:  0.0948\n\n✓ Results saved\n","output_type":"stream"}],"execution_count":16},{"id":"e380dbdc-f766-4fa3-8768-d097515d1fe2","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}