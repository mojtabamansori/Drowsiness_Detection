{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3744cfc9",
   "metadata": {
    "papermill": {
     "duration": 0.004476,
     "end_time": "2026-01-03T07:10:54.193765",
     "exception": false,
     "start_time": "2026-01-03T07:10:54.189289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 0 — Pipeline Switches (0/1)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f38ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:10:54.202999Z",
     "iopub.status.busy": "2026-01-03T07:10:54.202624Z",
     "iopub.status.idle": "2026-01-03T07:10:54.216146Z",
     "shell.execute_reply": "2026-01-03T07:10:54.215159Z"
    },
    "papermill": {
     "duration": 0.021324,
     "end_time": "2026-01-03T07:10:54.219057",
     "exception": false,
     "start_time": "2026-01-03T07:10:54.197733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline mode:\n",
    "# 0 = CNN on time-series (your current Torch training)\n",
    "# 1 = Feature-based ML (Logistic Regression with optional feature selection + postprocess)\n",
    "PIPELINE_MODE = 1\n",
    "\n",
    "# Section switches (0/1)\n",
    "ENABLE_FEATURE_EXTRACTION = 1\n",
    "ENABLE_FEATURE_SELECTION = 0\n",
    "ENABLE_POSTPROCESSING = 1\n",
    "\n",
    "# Recommended presets:\n",
    "# - CNN pipeline: PIPELINE_MODE=0, ENABLE_FEATURE_EXTRACTION=0, ENABLE_FEATURE_SELECTION=0\n",
    "# - Feature pipeline: PIPELINE_MODE=1, ENABLE_FEATURE_EXTRACTION=1, ENABLE_FEATURE_SELECTION=1\n",
    "\n",
    "# Feature extraction settings (used when ENABLE_FEATURE_EXTRACTION=1)\n",
    "FS = 128.0  # sampling rate (Hz). Change if your dataset uses a different FS.\n",
    "\n",
    "BANDS = {\n",
    "    \"delta\": (0.5, 4.0),\n",
    "    \"theta\": (4.0, 8.0),\n",
    "    \"alpha\": (8.0, 13.0),\n",
    "    \"beta\":  (13.0, 30.0),\n",
    "    \"gamma\": (30.0, 45.0),\n",
    "}\n",
    "\n",
    "# Feature selection settings (used when ENABLE_FEATURE_SELECTION=1)\n",
    "FEATURE_SELECTION_METHOD = \"f_classif\"  # \"f_classif\" or \"mutual_info\"\n",
    "FEATURE_K = 200  # number of selected features (top-K)\n",
    "\n",
    "# Post-processing settings (used when ENABLE_POSTPROCESSING=1)\n",
    "SMOOTH_WINDOW = 5  # odd integer recommended (e.g., 3,5,7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e1c40",
   "metadata": {
    "papermill": {
     "duration": 0.003485,
     "end_time": "2026-01-03T07:10:54.226461",
     "exception": false,
     "start_time": "2026-01-03T07:10:54.222976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 1 — Preprocessing\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db04e9e4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-03T07:10:54.235609Z",
     "iopub.status.busy": "2026-01-03T07:10:54.235069Z",
     "iopub.status.idle": "2026-01-03T07:11:22.144015Z",
     "shell.execute_reply": "2026-01-03T07:11:22.142866Z"
    },
    "papermill": {
     "duration": 27.916094,
     "end_time": "2026-01-03T07:11:22.145976",
     "exception": false,
     "start_time": "2026-01-03T07:10:54.229882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Installation completed\n",
      "total 173M\r\n",
      "-rw-r--r-- 1 root root 173M Jan  3 07:11 dataset.mat\r\n",
      "---------- 1 root root  31K Jan  3 07:10 __notebook__.ipynb\r\n",
      "\n",
      "✓ Dataset copied\n",
      "======================================================================\n",
      "Settings:\n",
      "  Bipolar: True\n",
      "  Overlap: True\n",
      "  Z-score: True\n",
      "  Runs: 2\n",
      "  Epochs: 11\n",
      "======================================================================\n",
      "\n",
      "Using device: cpu\n",
      "\n",
      "[1] Loading dataset...\n",
      "✓ Shape: (2022, 30, 384)\n",
      "\n",
      "[2] Preprocessing...\n",
      "  -> Applying bipolar montage...\n",
      "    Channels: 30 -> 32\n",
      "  -> Applying overlap augmentation...\n",
      "    Samples: 2022 -> 6064\n",
      "  -> Applying subject-wise z-score normalization...\n",
      "    Mean: 0.0000\n",
      "✓ Final shape: (6064, 32, 384)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q torch scipy scikit-learn\n",
    "print(\"✓ Installation completed\")\n",
    "\n",
    "# Copy dataset\n",
    "!cp \"/kaggle/input/dataset-drowsiness/dataset (1).mat\" /kaggle/working/dataset.mat\n",
    "\n",
    "# Check\n",
    "!ls -lh /kaggle/working/\n",
    "print(\"\\n✓ Dataset copied\")\n",
    "\n",
    "import os\n",
    "os.environ['TORCH_COMPILE_DISABLE'] = '1'\n",
    "os.environ['TORCHDYNAMO_DISABLE'] = '1'\n",
    "\n",
    "import torch\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Electrode indices\n",
    "fp1, fp2, f7 = 0, 1, 2\n",
    "f3, fz, f4 = 3, 4, 5\n",
    "f8, ft7, fc3 = 6, 7, 8\n",
    "fcz, fc4, ft8 = 9, 10, 11\n",
    "t3, c3, cz = 12, 13, 14\n",
    "c4, t4, tp7 = 15, 16, 17\n",
    "cp3, cpz, cp4 = 18, 19, 20\n",
    "tp8a1, t5, p3 = 21, 22, 23\n",
    "pz, p4, t6a2 = 24, 25, 26\n",
    "o1, oz, o2 = 27, 28, 29\n",
    "\n",
    "# Subject boundaries (original sample indices)\n",
    "startsub = np.zeros(11)\n",
    "finalsub = np.zeros(11)\n",
    "startsub[0] = 0\n",
    "finalsub[0] = 188\n",
    "startsub[1] = finalsub[0]\n",
    "finalsub[1] = 320\n",
    "startsub[2] = finalsub[1]\n",
    "finalsub[2] = 470\n",
    "startsub[3] = finalsub[2]\n",
    "finalsub[3] = 618\n",
    "startsub[4] = finalsub[3]\n",
    "finalsub[4] = 842\n",
    "startsub[5] = finalsub[4]\n",
    "finalsub[5] = 1008\n",
    "startsub[6] = finalsub[5]\n",
    "finalsub[6] = 1110\n",
    "startsub[7] = finalsub[6]\n",
    "finalsub[7] = 1374\n",
    "startsub[8] = finalsub[7]\n",
    "finalsub[8] = 1688\n",
    "startsub[9] = finalsub[8]\n",
    "finalsub[9] = 1796\n",
    "startsub[10] = finalsub[9]\n",
    "finalsub[10] = 2022\n",
    "\n",
    "\n",
    "def bipolar(xdata):\n",
    "    xdatabipolar = np.zeros((2022, 32, 384))\n",
    "    # vertical\n",
    "    # 1\n",
    "    xdatabipolar[:, 0, :] = xdata[:, fp1, :] - xdata[:, f7, :]\n",
    "    xdatabipolar[:, 1, :] = xdata[:, f7, :] - xdata[:, t3, :]\n",
    "    xdatabipolar[:, 2, :] = xdata[:, t3, :] - xdata[:, t5, :]\n",
    "    xdatabipolar[:, 3, :] = xdata[:, t5, :] - xdata[:, o1, :]\n",
    "    xdatabipolar[:, 4, :] = xdata[:, o1, :] - xdata[:, p3, :]\n",
    "    xdatabipolar[:, 5, :] = xdata[:, p3, :] - xdata[:, c3, :]\n",
    "    xdatabipolar[:, 6, :] = xdata[:, c3, :] - xdata[:, f3, :]\n",
    "    xdatabipolar[:, 7, :] = xdata[:, f3, :] - xdata[:, fp1, :]\n",
    "    # 2\n",
    "    xdatabipolar[:, 8, :] = xdata[:, pz, :] - xdata[:, cz, :]\n",
    "    xdatabipolar[:, 9, :] = xdata[:, cz, :] - xdata[:, fz, :]\n",
    "    # 3\n",
    "    xdatabipolar[:, 10, :] = xdata[:, fp2, :] - xdata[:, f8, :]\n",
    "    xdatabipolar[:, 11, :] = xdata[:, f8, :] - xdata[:, t4, :]\n",
    "    xdatabipolar[:, 12, :] = xdata[:, t4, :] - xdata[:, t6a2, :]\n",
    "    xdatabipolar[:, 13, :] = xdata[:, t6a2, :] - xdata[:, o2, :]\n",
    "    xdatabipolar[:, 14, :] = xdata[:, o2, :] - xdata[:, p4, :]\n",
    "    xdatabipolar[:, 15, :] = xdata[:, p4, :] - xdata[:, c4, :]\n",
    "    xdatabipolar[:, 16, :] = xdata[:, c4, :] - xdata[:, f4, :]\n",
    "    xdatabipolar[:, 17, :] = xdata[:, f4, :] - xdata[:, fp2, :]\n",
    "    # horizontal\n",
    "    # 4\n",
    "    xdatabipolar[:, 18, :] = xdata[:, fp1, :] - xdata[:, fp2, :]\n",
    "    xdatabipolar[:, 19, :] = xdata[:, f8, :] - xdata[:, f4, :]\n",
    "    xdatabipolar[:, 20, :] = xdata[:, f4, :] - xdata[:, fz, :]\n",
    "    xdatabipolar[:, 21, :] = xdata[:, fz, :] - xdata[:, f3, :]\n",
    "    xdatabipolar[:, 22, :] = xdata[:, f3, :] - xdata[:, f7, :]\n",
    "    # 5\n",
    "    xdatabipolar[:, 23, :] = xdata[:, t3, :] - xdata[:, c3, :]\n",
    "    xdatabipolar[:, 24, :] = xdata[:, c3, :] - xdata[:, cz, :]\n",
    "    xdatabipolar[:, 25, :] = xdata[:, cz, :] - xdata[:, c4, :]\n",
    "    xdatabipolar[:, 26, :] = xdata[:, c4, :] - xdata[:, t4, :]\n",
    "    # 6\n",
    "    xdatabipolar[:, 27, :] = xdata[:, t5, :] - xdata[:, p3, :]\n",
    "    xdatabipolar[:, 28, :] = xdata[:, p3, :] - xdata[:, pz, :]\n",
    "    xdatabipolar[:, 29, :] = xdata[:, pz, :] - xdata[:, p4, :]\n",
    "    xdatabipolar[:, 30, :] = xdata[:, p4, :] - xdata[:, t6a2, :]\n",
    "    xdatabipolar[:, 31, :] = xdata[:, o2, :] - xdata[:, o1, :]\n",
    "    return xdatabipolar\n",
    "\n",
    "\n",
    "def zscoresubjective(xdatabipolar):\n",
    "    startsub = np.zeros(11)\n",
    "    finalsub = np.zeros(11)\n",
    "    startsub[0] = 0\n",
    "    finalsub[0] = 188 * 3 - 2\n",
    "    startsub[1] = finalsub[0]\n",
    "    finalsub[1] = 320 * 3 - 2\n",
    "    startsub[2] = finalsub[1]\n",
    "    finalsub[2] = 470 * 3 - 2\n",
    "    startsub[3] = finalsub[2]\n",
    "    finalsub[3] = 618 * 3 - 2\n",
    "    startsub[4] = finalsub[3]\n",
    "    finalsub[4] = 842 * 3 - 2\n",
    "    startsub[5] = finalsub[4]\n",
    "    finalsub[5] = 1008 * 3 - 2\n",
    "    startsub[6] = finalsub[5]\n",
    "    finalsub[6] = 1110 * 3 - 2\n",
    "    startsub[7] = finalsub[6]\n",
    "    finalsub[7] = 1374 * 3 - 2\n",
    "    startsub[8] = finalsub[7]\n",
    "    finalsub[8] = 1688 * 3 - 2\n",
    "    startsub[9] = finalsub[8]\n",
    "    finalsub[9] = 1796 * 3 - 2\n",
    "    startsub[10] = finalsub[9]\n",
    "    finalsub[10] = 2022 * 3 - 2\n",
    "\n",
    "    for i in range(0, 11):\n",
    "        xdatabipolar[int(startsub[i]):int(finalsub[i])] = stats.zscore(\n",
    "            xdatabipolar[int(startsub[i]):int(finalsub[i])]\n",
    "        )\n",
    "    return xdatabipolar\n",
    "\n",
    "\n",
    "def hamposhanisub(xdata, label, ncha):\n",
    "    n = len(xdata)\n",
    "    k = 3 * n - 2\n",
    "    newdata = np.zeros((k, ncha, 384))\n",
    "    newlabel = np.zeros((k))\n",
    "    leni1 = 0\n",
    "    for iindex in range(11):\n",
    "        s = startsub[iindex]\n",
    "        f = finalsub[iindex]\n",
    "        leni2 = leni1 + int(f - s)\n",
    "        for i in range(leni1, leni2 - 1):\n",
    "            newdata[(3 * i), :, :] = xdata[i, :, :]\n",
    "\n",
    "            newdata[(3 * i) + 1, :, :256] = xdata[i, :, 128:]\n",
    "            newdata[(3 * i) + 1, :, 256:] = xdata[i + 1, :, :128]\n",
    "\n",
    "            newdata[(3 * i) + 2, :, :128] = xdata[i, :, 256:]\n",
    "            newdata[(3 * i) + 2, :, 128:] = xdata[i + 1, :, :256]\n",
    "\n",
    "        for i in range(leni1, leni2 - 1):\n",
    "            newlabel[(3 * i)] = label[i]\n",
    "            newlabel[(3 * i) + 1] = label[i]\n",
    "            newlabel[(3 * i) + 2] = label[i + 1]\n",
    "        leni1 = leni2\n",
    "\n",
    "    startsub[0] = 0\n",
    "    finalsub[0] = 188 * 3 - 2\n",
    "    startsub[1] = finalsub[0]\n",
    "    finalsub[1] = 320 * 3 - 2\n",
    "    startsub[2] = finalsub[1]\n",
    "    finalsub[2] = 470 * 3 - 2\n",
    "    startsub[3] = finalsub[2]\n",
    "    finalsub[3] = 618 * 3 - 2\n",
    "    startsub[4] = finalsub[3]\n",
    "    finalsub[4] = 842 * 3 - 2\n",
    "    startsub[5] = finalsub[4]\n",
    "    finalsub[5] = 1008 * 3 - 2\n",
    "    startsub[6] = finalsub[5]\n",
    "    finalsub[6] = 1110 * 3 - 2\n",
    "    startsub[7] = finalsub[6]\n",
    "    finalsub[7] = 1374 * 3 - 2\n",
    "    startsub[8] = finalsub[7]\n",
    "    finalsub[8] = 1688 * 3 - 2\n",
    "    startsub[9] = finalsub[8]\n",
    "    finalsub[9] = 1796 * 3 - 2\n",
    "    startsub[10] = finalsub[9]\n",
    "    finalsub[10] = 2022 * 3 - 2\n",
    "\n",
    "    return newdata, newlabel, finalsub, startsub\n",
    "\n",
    "\n",
    "APPLY_BIPOLAR = True\n",
    "APPLY_OVERLAP = True\n",
    "APPLY_ZSCORE = True\n",
    "\n",
    "N_RUNS = 2\n",
    "N_EPOCHS = 11\n",
    "BATCH_SIZE = 50\n",
    "LEARNING_RATE = 0.001\n",
    "DATASET_PATH = 'dataset.mat'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Settings:\")\n",
    "print(f\"  Bipolar: {APPLY_BIPOLAR}\")\n",
    "print(f\"  Overlap: {APPLY_OVERLAP}\")\n",
    "print(f\"  Z-score: {APPLY_ZSCORE}\")\n",
    "print(f\"  Runs: {N_RUNS}\")\n",
    "print(f\"  Epochs: {N_EPOCHS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "print(\"\\n[1] Loading dataset...\")\n",
    "data = sio.loadmat(DATASET_PATH)\n",
    "original_data = np.array(data['EEGsample'])\n",
    "original_labels = np.array(data['substate']).flatten().astype(int)\n",
    "print(f\"✓ Shape: {original_data.shape}\")\n",
    "\n",
    "def create_subject_index():\n",
    "    subIdx = np.zeros(2022, dtype=int)\n",
    "    boundaries = [0, 188, 320, 470, 618, 842, 1008, 1110, 1374, 1688, 1796, 2022]\n",
    "    for i in range(11):\n",
    "        subIdx[boundaries[i]:boundaries[i + 1]] = i + 1\n",
    "    return subIdx\n",
    "\n",
    "print(\"\\n[2] Preprocessing...\")\n",
    "processed_data = original_data.copy()\n",
    "processed_labels = original_labels.copy()\n",
    "subIdx = create_subject_index()\n",
    "n_channels = 30\n",
    "\n",
    "if APPLY_BIPOLAR:\n",
    "    print(\"  -> Applying bipolar montage...\")\n",
    "    processed_data = bipolar(processed_data)\n",
    "    n_channels = 32\n",
    "    print(f\"    Channels: {original_data.shape[1]} -> {n_channels}\")\n",
    "\n",
    "if APPLY_OVERLAP:\n",
    "    print(\"  -> Applying overlap augmentation...\")\n",
    "    before = processed_data.shape[0]\n",
    "    processed_data, processed_labels, finalsub_aug, startsub_aug = hamposhanisub(\n",
    "        processed_data, processed_labels, n_channels\n",
    "    )\n",
    "    print(f\"    Samples: {before} -> {processed_data.shape[0]}\")\n",
    "\n",
    "    new_subIdx = np.zeros(processed_data.shape[0], dtype=int)\n",
    "    idx = 0\n",
    "    for subj in range(11):\n",
    "        n_augmented = int(finalsub_aug[subj] - (startsub_aug[subj] if subj == 0 else finalsub_aug[subj - 1]))\n",
    "        new_subIdx[idx:idx + n_augmented] = subj + 1\n",
    "        idx += n_augmented\n",
    "    subIdx = new_subIdx\n",
    "\n",
    "if APPLY_ZSCORE:\n",
    "    print(\"  -> Applying subject-wise z-score normalization...\")\n",
    "    processed_data = zscoresubjective(processed_data)\n",
    "    print(f\"    Mean: {np.mean(processed_data):.4f}\")\n",
    "\n",
    "print(f\"✓ Final shape: {processed_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aad23e",
   "metadata": {
    "papermill": {
     "duration": 0.003677,
     "end_time": "2026-01-03T07:11:22.153692",
     "exception": false,
     "start_time": "2026-01-03T07:11:22.150015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 2 — Feature Extraction\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7549ab79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:11:22.163913Z",
     "iopub.status.busy": "2026-01-03T07:11:22.163414Z",
     "iopub.status.idle": "2026-01-03T07:12:29.341730Z",
     "shell.execute_reply": "2026-01-03T07:12:29.340598Z"
    },
    "papermill": {
     "duration": 67.189429,
     "end_time": "2026-01-03T07:12:29.346875",
     "exception": false,
     "start_time": "2026-01-03T07:11:22.157446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Extraction] Computing EEG features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17/1758092842.py:5: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return np.trapz(psd[mask], freqs[mask])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Extraction] feature_X shape: (6064, 352)\n"
     ]
    }
   ],
   "source": [
    "def _bandpower_from_psd(freqs, psd, fmin, fmax):\n",
    "    mask = (freqs >= fmin) & (freqs < fmax)\n",
    "    if not np.any(mask):\n",
    "        return 0.0\n",
    "    return np.trapz(psd[mask], freqs[mask])\n",
    "\n",
    "def _hjorth_params(x):\n",
    "    x = np.asarray(x)\n",
    "    dx = np.diff(x)\n",
    "    ddx = np.diff(dx)\n",
    "    var_x = np.var(x) + 1e-12\n",
    "    var_dx = np.var(dx) + 1e-12\n",
    "    var_ddx = np.var(ddx) + 1e-12\n",
    "    activity = var_x\n",
    "    mobility = np.sqrt(var_dx / var_x)\n",
    "    complexity = np.sqrt(var_ddx / var_dx) / (mobility + 1e-12)\n",
    "    return activity, mobility, complexity\n",
    "\n",
    "def extract_eeg_features(X, fs, bands):\n",
    "    # X: (N, C, T)\n",
    "    N, C, T = X.shape\n",
    "    freqs = np.fft.rfftfreq(T, d=1.0 / fs)\n",
    "    feats = []\n",
    "\n",
    "    for i in range(N):\n",
    "        sample_feats = []\n",
    "        for ch in range(C):\n",
    "            x = X[i, ch, :]\n",
    "            x = x - np.mean(x)\n",
    "\n",
    "            fft = np.fft.rfft(x)\n",
    "            psd = (np.abs(fft) ** 2) / (T + 1e-12)\n",
    "\n",
    "            band_powers = {}\n",
    "            total_power = _bandpower_from_psd(freqs, psd, 0.5, 45.0) + 1e-12\n",
    "            for name, (fmin, fmax) in bands.items():\n",
    "                bp = _bandpower_from_psd(freqs, psd, fmin, fmax)\n",
    "                band_powers[name] = bp\n",
    "\n",
    "            # Relative bandpowers\n",
    "            rel = [band_powers[k] / total_power for k in [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]]\n",
    "\n",
    "            # Ratios often useful for drowsiness\n",
    "            theta_alpha = band_powers[\"theta\"] / (band_powers[\"alpha\"] + 1e-12)\n",
    "            theta_beta = band_powers[\"theta\"] / (band_powers[\"beta\"] + 1e-12)\n",
    "            (act, mob, comp) = _hjorth_params(x)\n",
    "\n",
    "            # Spectral entropy (0..1)\n",
    "            p = psd / (np.sum(psd) + 1e-12)\n",
    "            spec_entropy = -np.sum(p * np.log(p + 1e-12)) / (np.log(len(p)) + 1e-12)\n",
    "\n",
    "            sample_feats.extend(rel)\n",
    "            sample_feats.extend([theta_alpha, theta_beta])\n",
    "            sample_feats.extend([act, mob, comp])\n",
    "            sample_feats.append(spec_entropy)\n",
    "\n",
    "        feats.append(sample_feats)\n",
    "\n",
    "    return np.asarray(feats, dtype=np.float64)\n",
    "\n",
    "feature_X = None\n",
    "feature_y = None\n",
    "feature_groups = None\n",
    "\n",
    "if ENABLE_FEATURE_EXTRACTION == 1:\n",
    "    print(\"[Feature Extraction] Computing EEG features...\")\n",
    "    feature_X = extract_eeg_features(processed_data, FS, BANDS)\n",
    "    feature_y = processed_labels.astype(int).copy()\n",
    "    feature_groups = subIdx.astype(int).copy()\n",
    "    print(f\"[Feature Extraction] feature_X shape: {feature_X.shape}\")\n",
    "else:\n",
    "    print(\"[Feature Extraction] Disabled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50751b73",
   "metadata": {
    "papermill": {
     "duration": 0.003902,
     "end_time": "2026-01-03T07:12:29.354730",
     "exception": false,
     "start_time": "2026-01-03T07:12:29.350828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 3 — Feature Selection\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9e78c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:12:29.364431Z",
     "iopub.status.busy": "2026-01-03T07:12:29.363990Z",
     "iopub.status.idle": "2026-01-03T07:12:29.727840Z",
     "shell.execute_reply": "2026-01-03T07:12:29.726493Z"
    },
    "papermill": {
     "duration": 0.371296,
     "end_time": "2026-01-03T07:12:29.729959",
     "exception": false,
     "start_time": "2026-01-03T07:12:29.358663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Feature Selection] Ready (applied inside training loop if enabled)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "\n",
    "def fit_transform_selector(X_train, y_train, X_test, method=\"f_classif\", k=200):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    if k is None or k <= 0 or k >= X_train_s.shape[1]:\n",
    "        return X_train_s, X_test_s, scaler, None\n",
    "\n",
    "    if method == \"mutual_info\":\n",
    "        selector = SelectKBest(mutual_info_classif, k=k)\n",
    "    else:\n",
    "        selector = SelectKBest(f_classif, k=k)\n",
    "\n",
    "    X_train_sel = selector.fit_transform(X_train_s, y_train)\n",
    "    X_test_sel = selector.transform(X_test_s)\n",
    "    return X_train_sel, X_test_sel, scaler, selector\n",
    "\n",
    "print(\"[Feature Selection] Ready (applied inside training loop if enabled)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cdf924",
   "metadata": {
    "papermill": {
     "duration": 0.004243,
     "end_time": "2026-01-03T07:12:29.738413",
     "exception": false,
     "start_time": "2026-01-03T07:12:29.734170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 4 — Model Training\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4462b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:12:29.749848Z",
     "iopub.status.busy": "2026-01-03T07:12:29.749361Z",
     "iopub.status.idle": "2026-01-03T07:13:19.303937Z",
     "shell.execute_reply": "2026-01-03T07:13:19.303063Z"
    },
    "papermill": {
     "duration": 49.563304,
     "end_time": "2026-01-03T07:13:19.306277",
     "exception": false,
     "start_time": "2026-01-03T07:12:29.742973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training] PIPELINE_MODE=1\n",
      "\n",
      "======================================================================\n",
      "Run 1/2\n",
      "======================================================================\n",
      "  Subject  1: 0.7171\n",
      "  Subject  2: 0.9015\n",
      "  Subject  3: 0.7289\n",
      "  Subject  4: 0.6757\n",
      "  Subject  5: 0.8140\n",
      "  Subject  6: 0.7892\n",
      "  Subject  7: 0.6307\n",
      "  Subject  8: 0.6503\n",
      "  Subject  9: 0.8493\n",
      "  Subject 10: 0.8827\n",
      "  Subject 11: 0.7301\n",
      "Run mean: 0.7608\n",
      "\n",
      "======================================================================\n",
      "Run 2/2\n",
      "======================================================================\n",
      "  Subject  1: 0.7171\n",
      "  Subject  2: 0.9015\n",
      "  Subject  3: 0.7289\n",
      "  Subject  4: 0.6757\n",
      "  Subject  5: 0.8140\n",
      "  Subject  6: 0.7892\n",
      "  Subject  7: 0.6307\n",
      "  Subject  8: 0.6503\n",
      "  Subject  9: 0.8493\n",
      "  Subject 10: 0.8827\n",
      "  Subject 11: 0.7301\n",
      "Run mean: 0.7608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class InterpretableCNN(nn.Module):\n",
    "    def __init__(self, n_channels=30):\n",
    "        super().__init__()\n",
    "        self.temp_conv = nn.Conv2d(1, 40, (1, 64), bias=False)\n",
    "        self.spat_conv = nn.Conv2d(40, 40, (n_channels, 1), bias=False)\n",
    "        self.bn = nn.BatchNorm2d(40, track_running_stats=False)\n",
    "        self.pool = nn.AvgPool2d((1, 8))\n",
    "        self.fc = nn.Linear(40 * ((384 - 64 + 1) // 8), 2)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.temp_conv(x)\n",
    "        x = self.spat_conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = torch.square(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.log(torch.clamp(x, min=1e-6))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return self.log_softmax(x)\n",
    "\n",
    "\n",
    "print(f\"[Training] PIPELINE_MODE={PIPELINE_MODE}\")\n",
    "all_results = np.zeros((N_RUNS, 11))\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    print(f\"\\n{'=' * 70}\")\n",
    "    print(f\"Run {run + 1}/{N_RUNS}\")\n",
    "    print(f\"{'=' * 70}\")\n",
    "\n",
    "    torch.manual_seed(run)\n",
    "    np.random.seed(run)\n",
    "\n",
    "    for test_subj in range(1, 12):\n",
    "        train_mask = (subIdx != test_subj)\n",
    "        test_mask = (subIdx == test_subj)\n",
    "\n",
    "        if PIPELINE_MODE == 0:\n",
    "            # CNN on time-series\n",
    "            x_train = processed_data[train_mask].reshape(-1, 1, n_channels, 384)\n",
    "            y_train = processed_labels[train_mask].astype(np.longlong)\n",
    "            x_test = processed_data[test_mask].reshape(-1, 1, n_channels, 384)\n",
    "            y_test = processed_labels[test_mask].astype(np.longlong)\n",
    "\n",
    "            train_dataset = torch.utils.data.TensorDataset(\n",
    "                torch.from_numpy(x_train), torch.from_numpy(y_train)\n",
    "            )\n",
    "            train_loader = torch.utils.data.DataLoader(\n",
    "                train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    "            )\n",
    "\n",
    "            model = InterpretableCNN(n_channels=n_channels).double().to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            criterion = nn.NLLLoss()\n",
    "\n",
    "            model.train()\n",
    "            for epoch in range(N_EPOCHS):\n",
    "                for batch_x, batch_y in train_loader:\n",
    "                    batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(batch_x)\n",
    "                    loss = criterion(output, batch_y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                x_test_t = torch.DoubleTensor(x_test).to(device)\n",
    "                pred = model(x_test_t).cpu().numpy().argmax(axis=1)\n",
    "                acc = accuracy_score(y_test, pred)\n",
    "\n",
    "            all_results[run, test_subj - 1] = acc\n",
    "            print(f\"  Subject {test_subj:2d}: {acc:.4f}\")\n",
    "\n",
    "            del model\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        else:\n",
    "            # Feature-based ML\n",
    "            if feature_X is None or feature_y is None or feature_groups is None:\n",
    "                raise RuntimeError(\"Feature extraction is required for PIPELINE_MODE=1. Set ENABLE_FEATURE_EXTRACTION=1.\")\n",
    "\n",
    "            X_train = feature_X[train_mask]\n",
    "            y_train = feature_y[train_mask]\n",
    "            X_test = feature_X[test_mask]\n",
    "            y_test = feature_y[test_mask]\n",
    "\n",
    "            if ENABLE_FEATURE_SELECTION == 1:\n",
    "                X_train, X_test, scaler, selector = fit_transform_selector(\n",
    "                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=FEATURE_K\n",
    "                )\n",
    "            else:\n",
    "                X_train, X_test, scaler, selector = fit_transform_selector(\n",
    "                    X_train, y_train, X_test, method=FEATURE_SELECTION_METHOD, k=0\n",
    "                )\n",
    "\n",
    "            clf = LogisticRegression(\n",
    "                max_iter=2000,\n",
    "                class_weight=\"balanced\",\n",
    "                random_state=run,\n",
    "                n_jobs=None\n",
    "            )\n",
    "            clf.fit(X_train, y_train)\n",
    "            pred = clf.predict(X_test)\n",
    "            acc = accuracy_score(y_test, pred)\n",
    "\n",
    "            all_results[run, test_subj - 1] = acc\n",
    "            print(f\"  Subject {test_subj:2d}: {acc:.4f}\")\n",
    "\n",
    "    print(f\"Run mean: {np.mean(all_results[run]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36901c0",
   "metadata": {
    "papermill": {
     "duration": 0.017212,
     "end_time": "2026-01-03T07:13:19.341505",
     "exception": false,
     "start_time": "2026-01-03T07:13:19.324293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 5 — Post-processing\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc28ac09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:13:19.379376Z",
     "iopub.status.busy": "2026-01-03T07:13:19.376140Z",
     "iopub.status.idle": "2026-01-03T07:13:19.392845Z",
     "shell.execute_reply": "2026-01-03T07:13:19.391922Z"
    },
    "papermill": {
     "duration": 0.038218,
     "end_time": "2026-01-03T07:13:19.396419",
     "exception": false,
     "start_time": "2026-01-03T07:13:19.358201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Post-processing] Ready (apply in evaluation if enabled)\n"
     ]
    }
   ],
   "source": [
    "def smooth_predictions(pred, window=5):\n",
    "    pred = np.asarray(pred).astype(int)\n",
    "    if window is None or window <= 1:\n",
    "        return pred\n",
    "    if window % 2 == 0:\n",
    "        window += 1\n",
    "\n",
    "    pad = window // 2\n",
    "    padded = np.pad(pred, (pad, pad), mode=\"edge\")\n",
    "    out = pred.copy()\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        w = padded[i:i + window]\n",
    "        out[i] = 1 if np.mean(w) >= 0.5 else 0\n",
    "    return out\n",
    "\n",
    "print(\"[Post-processing] Ready (apply in evaluation if enabled)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5664ed88",
   "metadata": {
    "papermill": {
     "duration": 0.008101,
     "end_time": "2026-01-03T07:13:19.416851",
     "exception": false,
     "start_time": "2026-01-03T07:13:19.408750",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 6 — Evaluation\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b6ba6f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-03T07:13:19.429139Z",
     "iopub.status.busy": "2026-01-03T07:13:19.428771Z",
     "iopub.status.idle": "2026-01-03T07:13:19.437042Z",
     "shell.execute_reply": "2026-01-03T07:13:19.436201Z"
    },
    "papermill": {
     "duration": 0.017233,
     "end_time": "2026-01-03T07:13:19.439360",
     "exception": false,
     "start_time": "2026-01-03T07:13:19.422127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Final Results\n",
      "======================================================================\n",
      "\n",
      "Accuracy per Subject:\n",
      "  Subject  1: 0.7171 ± 0.0000\n",
      "  Subject  2: 0.9015 ± 0.0000\n",
      "  Subject  3: 0.7289 ± 0.0000\n",
      "  Subject  4: 0.6757 ± 0.0000\n",
      "  Subject  5: 0.8140 ± 0.0000\n",
      "  Subject  6: 0.7892 ± 0.0000\n",
      "  Subject  7: 0.6307 ± 0.0000\n",
      "  Subject  8: 0.6503 ± 0.0000\n",
      "  Subject  9: 0.8493 ± 0.0000\n",
      "  Subject 10: 0.8827 ± 0.0000\n",
      "  Subject 11: 0.7301 ± 0.0000\n",
      "\n",
      "Overall mean: 0.7608\n",
      "Overall std:  0.0886\n",
      "\n",
      "✓ Results saved\n"
     ]
    }
   ],
   "source": [
    "# Optional: apply post-processing to stored results would require keeping per-subject predictions.\n",
    "# This cell provides final reporting for the current pipeline outputs (accuracy per subject).\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Final Results\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nAccuracy per Subject:\")\n",
    "for i in range(11):\n",
    "    mean = np.mean(all_results[:, i])\n",
    "    std = np.std(all_results[:, i])\n",
    "    print(f\"  Subject {i + 1:2d}: {mean:.4f} ± {std:.4f}\")\n",
    "\n",
    "print(f\"\\nOverall mean: {np.mean(all_results):.4f}\")\n",
    "print(f\"Overall std:  {np.std(all_results):.4f}\")\n",
    "\n",
    "np.save(\"results_final.npy\", all_results)\n",
    "print(\"\\n✓ Results saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8a56c",
   "metadata": {
    "papermill": {
     "duration": 0.005027,
     "end_time": "2026-01-03T07:13:19.449504",
     "exception": false,
     "start_time": "2026-01-03T07:13:19.444477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 9173680,
     "sourceId": 14366015,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9173706,
     "sourceId": 14366056,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 151.596978,
   "end_time": "2026-01-03T07:13:22.373589",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-03T07:10:50.776611",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
